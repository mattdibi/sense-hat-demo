# Kura AI Wire Component demo

Kura AI Wire Component SenseHat-based demo.

The goal of this repository is to demo the AI inference capabilites of Kura Wires through the use of [NVIDIA Triton Inference Server](https://developer.nvidia.com/nvidia-triton-inference-server). This project trains a [Autencoder](https://en.wikipedia.org/wiki/Autoencoder) in [Tensorflow](https://www.tensorflow.org/) using the data extracted from a Respberry Pi equipped with a [Sense HAT](https://www.raspberrypi.com/products/sense-hat/) with the goal of detecting anomalies in the data retrived by the Sense HAT.

## Project structure

The repository is organized in three main directories:
- **models**: is the Triton server [model repository](https://github.com/triton-inference-server/server/blob/main/docs/model_repository.md) and contains the trained models generated by the training environment.
- **training**: contains the training environment which is comprised of the dataset and the sources for generating the autoencoder model for anomaly detection.
- **snapshots**: contains the Kura snapshots for the Wire Graph used for training, the one used for the inference, and the pre-configured SenseHat driver and assets.

## Prerequisites

In order to be able to execute this demo on a RaspberryPi board, this requirements have to be met:
- Configured SenseHat: see [SenseHat documentation](https://www.raspberrypi.com/documentation/accessories/sense-hat.html)
- I2C interface should be unlocked using sudo `raspi-config`
- The following Deployment Packages must be installed: `org.eclipse.kura.ai.triton.server_*.dp`, `org.eclipse.kura.wire.ai.component.provider_*.dp`, `org.eclipse.kura.example.driver.sensehat_*.dp`
- Apply the [driver snapshot](snapshots/sensehat-driver.xml) and verify it works by selecting the "asset-sensehat" and clicking on "Data": a reading of the values should be succesfully triggered
- Apply the [H2Db configuration snapshot](snapshots/h2-config.xml): this will create a H2 web server running on http://192.168.2.8:9123 (use the raspberry IP address)
- Open port 9123 in Firewall

## Data collection

The [data colletion wire graph snapshot](snapshots/graph-data-collection.xml) allows to collect data in the "sensehat" table of the default H2DB instance.

To later extract the collected data in a CSV file, access the H2 web console using username `SA` and a blank password, and execute the following statement from the H2 web console:
```
CALL CSVWRITE ('/home/pi/data.csv', 'SELECT * FROM "sensehat"')
```
The data will be saved in CSV format under `/home/pi/data.csv`.

## Training

### Training environment setup

The creation of a Python virtual environment is highly recommended. Create a new environment with the following:

```bash
python3 -m venv .venv
```

Activate it with:

```bash
source .venv/bin/activate
```

Then update `pip` and install the training environment requirements:

```bash
pip3 install --upgrade pip
```

```bash
pip3 install -r training/requirements.txt
```

### Model training

Decompress the datasets

```bash
cd training && unzip *.zip
```

Train the model with the data provided in this repository with:

```bash
./train.py
```

Train script options:

```bash
usage: train.py [-h] [-t TRAIN_DATA_PATH] [-s SAVED_MODEL_NAME]

Training script for Kura AI Wire Component anomaly detection

optional arguments:
  -h, --help            show this help message and exit
  -t TRAIN_DATA_PATH, --train_data_path TRAIN_DATA_PATH
                        Path to .csv training set (default: new-train-raw.csv)
  -s SAVED_MODEL_NAME, --saved_model_name SAVED_MODEL_NAME
                        Folder where the trained model will be saved to (default: saved_model/autoencoder)
```

Move the trained model in the Triton model repository and rename it to `model.savedmodel`

```bash
mkdir models/tf_autoencoder_fp32/1/
```

```bash
cp -r training/saved_model/autoencoder models/tf_autoencoder_fp32/1/model.savedmodel
```

## Inference

For running these models inside Triton, navigate to this repository and run:

```bash
docker run --rm \
    -p4000:8000 \
    -p4001:8001 \
    -p4002:8002 \
    --shm-size=150m \
    -v $(pwd)/models:/models \
    nvcr.io/nvidia/tritonserver:22.01-py3 \
    tritonserver --model-repository=/models --model-control-mode=explicit
```

Excpected models folder structure:

```bash
models
├── postprocessor
│   ├── 1
│   │   └── model.py
│   └── config.pbtxt
├── preprocessor
│   ├── 1
│   │   └── model.py
│   └── config.pbtxt
└── tf_autoencoder_fp32
    ├── 1
    │   └── model.savedmodel
    │       ├── assets
    │       ├── keras_metadata.pb
    │       ├── saved_model.pb
    │       └── variables
    │           ├── variables.data-00000-of-00001
    │           └── variables.index
    └── config.pbtxt
```
